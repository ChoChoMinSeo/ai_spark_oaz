{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'seed':10,\n",
    "    'val_size':0.2,\n",
    "    'experiment':True,\n",
    "    'batch_size':8,\n",
    "    'lr':1e-3,\n",
    "    'epochs':50,\n",
    "    'early_stopping':10,\n",
    "    'inference':{\n",
    "        'threshold':0.8\n",
    "    }\n",
    "}\n",
    "DATAPATH='./sm_dataset'\n",
    "data_paths={\n",
    "    'train_csv': DATAPATH+'/sm_npy_train_meta.csv' if config['experiment'] else DATAPATH+'/train_meta.csv',\n",
    "    'test_csv': DATAPATH+'/test_meta.csv',\n",
    "    'train_img':DATAPATH+'/npy_train_img/',\n",
    "    'train_mask':DATAPATH+'/npy_train_mask/'\n",
    "}\n",
    "train_csv = pd.read_csv(data_paths['train_csv'])\n",
    "test_csv = pd.read_csv(data_paths['test_csv'])\n",
    "SAVE_PATH = './logs'\n",
    "save_paths={\n",
    "    'model':SAVE_PATH+'/models/',\n",
    "    'val':SAVE_PATH+'/vals/'\n",
    "}\n",
    "# 시드 고정 함수\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "fix_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wildfire_Dataset(Dataset):\n",
    "    def __init__(self, csv, img_transform=None,mask_transform = None,infer=False):\n",
    "        self.csv = csv\n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.infer = infer\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.csv.iloc[idx,0]\n",
    "        image = np.load(data_paths['train_img']+img_path).transpose(2,0,1)\n",
    "        # test인 경우 infer==True\n",
    "        if self.infer:\n",
    "            if self.img_transform:\n",
    "                for i in range(10):\n",
    "                    image[i] = self.img_transform(image)\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.csv.iloc[idx,1]\n",
    "        mask = np.load(data_paths['train_mask']+mask_path)\n",
    "        if self.img_transform:\n",
    "            for i in range(10):\n",
    "                image[i] = self.img_transform(image[i])\n",
    "            mask = torch.from_numpy(self.mask_transform(mask))\n",
    "            \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # transforms.ToTensor(),\n",
    "    ]),\n",
    "    'valid':transforms.Compose([\n",
    "        # transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        # transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "img_transforms={\n",
    "    'train': transforms.Compose([\n",
    "        mask_transforms['train'],\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ]),\n",
    "    'valid':transforms.Compose([\n",
    "        mask_transforms['valid'],\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        mask_transforms['valid'],\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(data_paths['train_mask']+'/train_mask_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = transforms.ToTensor()\n",
    "tr(mask).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 16, valid size: 4\n"
     ]
    }
   ],
   "source": [
    "train_csv_, valid_csv_ = train_test_split(train_csv,test_size=config['val_size'],random_state=config['seed'])\n",
    "train_dataset = Wildfire_Dataset(train_csv_,img_transform=img_transforms['train'],mask_transform=mask_transforms['train'],infer=False)\n",
    "valid_dataset = Wildfire_Dataset(valid_csv_,img_transform=img_transforms['valid'],mask_transform=mask_transforms['valid'],infer=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'],shuffle=False)\n",
    "print(f'train size: {len(train_dataset)}, valid size: {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name='efficientnet-b7',\n",
    "    encoder_weights = 'imagenet',\n",
    "    in_channels=10,\n",
    "    classes=1,\n",
    ")\n",
    "torch.save(model.state_dict(), save_paths[\"model\"]+'/base_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(config, model, criterion, valid_loader,epoch):\n",
    "    model.eval()\n",
    "    valid_loss=0\n",
    "    y_pred_dict={}\n",
    "    with torch.no_grad():\n",
    "        for idx,(images, masks) in tqdm(enumerate(valid_loader)):\n",
    "            images = images.to(config['device'],dtype = torch.float32)\n",
    "            masks = masks.to(config['device'],dtype = torch.float32)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            valid_loss +=loss.item()\n",
    "            \n",
    "            output_masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "            output_masks = np.squeeze(output_masks, axis=1)\n",
    "            \n",
    "            for i in range(len(output_masks)):\n",
    "                y_pred = np.where(output_masks[i,:,:]>config['inference']['threshold'],1,0).astype(np.uint8)\n",
    "                y_pred_dict[idx*config['batch_size']+i] = y_pred\n",
    "        joblib.dump(y_pred_dict,save_paths['val']+f'epoch: {epoch}.pkl')\n",
    "    return valid_loss/len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, model, train_loader, valid_loader):\n",
    "    model = model.to(config['device'])\n",
    "    es_count = 0\n",
    "    min_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-8, verbose=True)\n",
    "    print('***TRAINING START***')\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        epoch_loss=0\n",
    "        for images, masks in tqdm(train_loader):\n",
    "            images = images.to(config['device'],dtype = torch.float32)\n",
    "            masks = masks.to(config['device'],dtype = torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss+=loss.item()\n",
    "        \n",
    "        val_loss = validation(config, model, criterion, valid_loader, epoch)\n",
    "        \n",
    "        es_count += 1\n",
    "        if min_val_loss > val_loss:\n",
    "            es_count = 0\n",
    "            min_val_loss = val_loss\n",
    "            best_model = model\n",
    "            state_dict = model.state_dict()\n",
    "            best_epoch = epoch+1\n",
    "            print(f\"Epoch [{best_epoch}] New Minimum Valid Loss!\")\n",
    "            print(\"..save current best model..\")\n",
    "            model_name = f'epoch {epoch}_current_best_model.pt'\n",
    "            torch.save(state_dict, save_paths['model']+'/'+model_name)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if es_count == config['early_stopping']:\n",
    "            print(f\"Early Stopping Count에 도달했습니다!\")\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, Best Epoch: {best_epoch}\")\n",
    "            print(\"***TRAINING DONE***\")\n",
    "            return best_model\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, ES Count: {es_count}\")\n",
    "        print(\"------------------------------------------------------------------------------------\")\n",
    "    print(f\"Early Stopping Count에 도달하지 않았습니다! \\nEarly Stopping Count: {config['early_stopping']} Best Epoch: {best_epoch}\")\n",
    "    print(\"***TRAINING DONE***\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train(config,model,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dict = {}\n",
    "\n",
    "for i in test_csv['test_img']:\n",
    "    y_pred = model.predict(np.array([img]), batch_size=1)\n",
    "\n",
    "    y_pred = np.where(y_pred[0, :, :, 0] > 0.25, 1, 0) # 임계값 처리\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred_dict[i] = y_pred\n",
    "\n",
    "joblib.dump(y_pred_dict, './y_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
